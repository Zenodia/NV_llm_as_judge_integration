{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b545101f-7525-4b65-9f42-1a79325ac2e7",
   "metadata": {},
   "source": [
    "---\n",
    "## per given query , search documents using NeMo Retriever ( once it is up and running ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef37973-100b-4583-9b60-66eabf4e42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_nvidia_ai_endpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e1226-747c-412f-89b1-d036208a51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the NVIDIA_API_KEY as environment variable \n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n",
    "global nvapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4819a7ac-4454-49b0-9564-9e343aca15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96320af-ae89-4f4a-9298-274ea45ce854",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPADDRESS = \"rag-server\" if os.environ.get(\"AI_WORKBENCH\", \"false\") == \"true\" else \"localhost\" #Replace this with the correct IP address\n",
    "RAG_SERVER_PORT = \"8081\"\n",
    "BASE_URL = f\"http://{IPADDRESS}:{RAG_SERVER_PORT}\"  # Replace with your server URL\n",
    "\n",
    "async def print_response(response):\n",
    "    \"\"\"Helper to print API response.\"\"\"\n",
    "    try:\n",
    "        response_json = await response.json()\n",
    "        output = json.dumps(response_json, indent=2)\n",
    "        print(json.dumps(response_json, indent=2))\n",
    "    except aiohttp.ClientResponseError:\n",
    "        print(await response.text())\n",
    "        output=\"error\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9dd4e9-9c9a-44d1-aed8-d90d8b238c3a",
   "metadata": {},
   "source": [
    "## check the self-served nemo retriever endpoints is healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de54d95-08d1-4f96-b1e4-278425a8f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"message\": \"Service is up.\",\n",
      "  \"databases\": [\n",
      "    {\n",
      "      \"service\": \"Milvus\",\n",
      "      \"url\": \"http://milvus:19530\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"latency_ms\": 205.8,\n",
      "      \"error\": null,\n",
      "      \"collections\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"object_storage\": [\n",
      "    {\n",
      "      \"service\": \"MinIO\",\n",
      "      \"url\": \"minio:9010\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"latency_ms\": 4.99,\n",
      "      \"error\": null,\n",
      "      \"buckets\": 2,\n",
      "      \"message\": null\n",
      "    }\n",
      "  ],\n",
      "  \"nim\": [\n",
      "    {\n",
      "      \"service\": \"LLM (nvidia/llama-3.3-nemotron-super-49b-v1.5)\",\n",
      "      \"url\": \"NVIDIA API Catalog\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"latency_ms\": 0.0,\n",
      "      \"error\": null,\n",
      "      \"message\": \"Using NVIDIA API Catalog\",\n",
      "      \"http_status\": null\n",
      "    },\n",
      "    {\n",
      "      \"service\": \"Embeddings (nvidia/llama-3.2-nv-embedqa-1b-v2)\",\n",
      "      \"url\": \"NVIDIA API Catalog\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"latency_ms\": 0.0,\n",
      "      \"error\": null,\n",
      "      \"message\": \"Using NVIDIA API Catalog\",\n",
      "      \"http_status\": null\n",
      "    },\n",
      "    {\n",
      "      \"service\": \"Ranking (nvidia/llama-3.2-nv-rerankqa-1b-v2)\",\n",
      "      \"url\": \"NVIDIA API Catalog\",\n",
      "      \"status\": \"healthy\",\n",
      "      \"latency_ms\": 0.0,\n",
      "      \"error\": null,\n",
      "      \"message\": \"Using NVIDIA API Catalog\",\n",
      "      \"http_status\": null\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def fetch_health_status():\n",
    "    \"\"\"Fetch health status asynchronously.\"\"\"\n",
    "    url = f\"{BASE_URL}/v1/health\"\n",
    "    params = {\"check_dependencies\": \"True\"} # Check health of dependencies as well\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url, params=params) as response:\n",
    "            await print_response(response)\n",
    "\n",
    "# Run the async function\n",
    "await fetch_health_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc742f-2a44-4cf2-9432-a78909c3bed6",
   "metadata": {},
   "source": [
    "## submit user query and search the documents with default config specifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365fc85b-daf8-4642-8694-1e3bd930b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"total_results\": 2,\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"document_id\": \"\",\n",
      "      \"content\": \"24,721 million for 2024 (2023: DKK 25,970 million), a decrease \\r\\nof 3.6% in constant currencies. The decline in gross profit was driven by lower \\r\\naverage gross profit yields compared to the previous year, offset by higher volumes \\r\\nin both air and sea. For the second half of 2024, gross profit improved on a year\\u0002over-year basis due to strong volume growth and a stable yield development. The \\r\\nsituation in the Red Sea had a slightly positive impact on sea freight yields in 2024, \\r\\npartly offsetting the overall decline in average sea freight yields on a full-year basis.\\r\\nIn a competitive market, the division maintained its focus on pricing discipline \\r\\nand high-margin business. We saw a positive development with our largest \\r\\ncustomers as well as in our targeted industry verticals, and we continued to \\r\\nsee good momentum with our customers in the small- and midsize segment.\\r\\nThe division\\u2019s gross margin was 23.7% for 2024 (2023: 27.9%). The develop\\u0002ment was driven by the increase in the division\\u2019s revenue, which was due to the \\r\\nhigher average freight rates in the market, and partly by the lower average \\r\\ngross profit yields compared to 2023.\\r\\nEBIT before special items was DKK 11,888 million (2023: DKK 13,363 million), \\r\\na decline of 9.9% in constant currencies, reflecting a margin of 11.4% (2023: \\r\\n14.4%). The decline in EBIT before special items can be attributed to lower \\r\\ngross profit in the first half of the year compared to the same period in the \\r\\nprevious year as well as cost inflation. Our digitalisation efforts in the past year \\r\\nhave enabled productivity improvements and cost reductions. Furthermore, the \\r\\ndivision has implemented several cost reduction initiatives to reduce staff costs \\r\\nand other external costs since 2023. The impact of the initiatives has been \\r\\npartly offset by increased activity levels with higher volume for both air and \\r\\nsea in combination with cost inflation.\\r\\nThe conversion ratio was 48.1%, compared to 51.5% last year. The conversion \\r\\nratio was negatively affected by lower gross profit in the first six months \\r\\ncompared to the same period in the previous year. This was partly offset by \\r\\nproductivity gains related to digitalisation and cost-saving initiatives. The con\\u0002version ratio was at an extraordinary high level in 2023 and above our financial \\r\\ntarget for 2026 due to the market conditions. During 2024, we have seen a \\r\\nstabilisation of the conversion \",\n",
      "      \"document_name\": \"DSVAnnualReport2024.pdf\",\n",
      "      \"document_type\": \"text\",\n",
      "      \"score\": 0.75722034035404,\n",
      "      \"metadata\": {\n",
      "        \"language\": \"\",\n",
      "        \"date_created\": \"\",\n",
      "        \"last_modified\": \"\",\n",
      "        \"page_number\": 0,\n",
      "        \"description\": \"24,721 million for 2024 (2023: DKK 25,970 million), a decrease \\r\\nof 3.6% in constant currencies. The decline in gross profit was driven by lower \\r\\naverage gross profit yields compared to the previous year, offset by higher volumes \\r\\nin both air and sea. For the second half of 2024, gross profit improved on a year\\u0002over-year basis due to strong volume growth and a stable yield development. The \\r\\nsituation in the Red Sea had a slightly positive impact on sea freight yields in 2024, \\r\\npartly offsetting the overall decline in average sea freight yields on a full-year basis.\\r\\nIn a competitive market, the division maintained its focus on pricing discipline \\r\\nand high-margin business. We saw a positive development with our largest \\r\\ncustomers as well as in our targeted industry verticals, and we continued to \\r\\nsee good momentum with our customers in the small- and midsize segment.\\r\\nThe division\\u2019s gross margin was 23.7% for 2024 (2023: 27.9%). The develop\\u0002ment was driven by the increase in the division\\u2019s revenue, which was due to the \\r\\nhigher average freight rates in the market, and partly by the lower average \\r\\ngross profit yields compared to 2023.\\r\\nEBIT before special items was DKK 11,888 million (2023: DKK 13,363 million), \\r\\na decline of 9.9% in constant currencies, reflecting a margin of 11.4% (2023: \\r\\n14.4%). The decline in EBIT before special items can be attributed to lower \\r\\ngross profit in the first half of the year compared to the same period in the \\r\\nprevious year as well as cost inflation. Our digitalisation efforts in the past year \\r\\nhave enabled productivity improvements and cost reductions. Furthermore, the \\r\\ndivision has implemented several cost reduction initiatives to reduce staff costs \\r\\nand other external costs since 2023. The impact of the initiatives has been \\r\\npartly offset by increased activity levels with higher volume for both air and \\r\\nsea in combination with cost inflation.\\r\\nThe conversion ratio was 48.1%, compared to 51.5% last year. The conversion \\r\\nratio was negatively affected by lower gross profit in the first six months \\r\\ncompared to the same period in the previous year. This was partly offset by \\r\\nproductivity gains related to digitalisation and cost-saving initiatives. The con\\u0002version ratio was at an extraordinary high level in 2023 and above our financial \\r\\ntarget for 2026 due to the market conditions. During 2024, we have seen a \\r\\nstabilisation of the conversion \",\n",
      "        \"height\": 0,\n",
      "        \"width\": 0,\n",
      "        \"location\": [],\n",
      "        \"location_max_dimensions\": [],\n",
      "        \"content_metadata\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"Unstructured text from PDF document.\",\n",
      "          \"page_number\": 23,\n",
      "          \"hierarchy\": {\n",
      "            \"page_count\": 159,\n",
      "            \"page\": 23,\n",
      "            \"block\": -1,\n",
      "            \"line\": -1,\n",
      "            \"span\": -1,\n",
      "            \"nearby_objects\": {\n",
      "              \"text\": {\n",
      "                \"content\": [],\n",
      "                \"bbox\": [],\n",
      "                \"type\": []\n",
      "              },\n",
      "              \"images\": {\n",
      "                \"content\": [],\n",
      "                \"bbox\": [],\n",
      "                \"type\": []\n",
      "              },\n",
      "              \"structured\": {\n",
      "                \"content\": [],\n",
      "                \"bbox\": [],\n",
      "                \"type\": []\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"subtype\": \"\",\n",
      "          \"location\": null,\n",
      "          \"max_dimensions\": null\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"document_id\": \"\",\n",
      "      \"content\": \"24,721 million for 2024 (2023: DKK 25,970 million), a decrease \\r\\nof 3.6% in constant currencies. The decline in gross profit was driven by lower \\r\\naverage gross profit yields compared to the previous year, offset by higher volumes \\r\\nin both air and sea. For the second half of 2024, gross profit improved on a year\\u0002over-year basis due to strong volume growth and a stable yield development. The \\r\\nsituation in the Red Sea had a slightly positive impact on sea freight yields in 2024, \\r\\npartly offsetting the overall decline in average sea freight yields on a full-year basis.\\r\\nIn a competitive market, the division maintained its focus on pricing discipline \\r\\nand high-margin business. We saw a positive development with our largest \\r\\ncustomers as well as in our targeted industry verticals, and we continued to \\r\\nsee good momentum with our customers in the small- and midsize segment.\\r\\nThe division\\u2019s gross margin was 23.7% for 2024 (2023: 27.9%). The develop\\u0002ment was driven by the increase in the division\\u2019s revenue, which was due to the \\r\\nhigher average freight rates in the market, and partly by the lower average \\r\\ngross profit yields compared to 2023.\\r\\nEBIT before special items was DKK 11,888 million (2023: DKK 13,363 million), \\r\\na decline of 9.9% in constant currencies, reflecting a margin of 11.4% (2023: \\r\\n14.4%). The decline in EBIT before special items can be attributed to lower \\r\\ngross profit in the first half of the year compared to the same period in the \\r\\nprevious year as well as cost inflation. Our digitalisation efforts in the past year \\r\\nhave enabled productivity improvements and cost reductions. Furthermore, the \\r\\ndivision has implemented several cost reduction initiatives to reduce staff costs \\r\\nand other external costs since 2023. The impact of the initiatives has been \\r\\npartly offset by increased activity levels with higher volume for both air and \\r\\nsea in combination with cost inflation.\\r\\nThe conversion ratio was 48.1%, compared to 51.5% last year. The conversion \\r\\nratio was negatively affected by lower gross profit in the first six months \\r\\ncompared to the same period in the previous year. This was partly offset by \\r\\nproductivity gains related to digitalisation and cost-saving initiatives. The con\\u0002version ratio was at an extraordinary high level in 2023 and above our financial \\r\\ntarget for 2026 due to the market conditions. During 2024, we have seen a \\r\\nstabilisation of the conversion \",\n",
      "      \"document_name\": \"DSVAnnualReport2024.pdf\",\n",
      "      \"document_type\": \"text\",\n",
      "      \"score\": 0.75722034035404,\n",
      "      \"metadata\": {\n",
      "        \"language\": \"\",\n",
      "        \"date_created\": \"\",\n",
      "        \"last_modified\": \"\",\n",
      "        \"page_number\": 0,\n",
      "        \"description\": \"24,721 million for 2024 (2023: DKK 25,970 million), a decrease \\r\\nof 3.6% in constant currencies. The decline in gross profit was driven by lower \\r\\naverage gross profit yields compared to the previous year, offset by higher volumes \\r\\nin both air and sea. For the second half of 2024, gross profit improved on a year\\u0002over-year basis due to strong volume growth and a stable yield development. The \\r\\nsituation in the Red Sea had a slightly positive impact on sea freight yields in 2024, \\r\\npartly offsetting the overall decline in average sea freight yields on a full-year basis.\\r\\nIn a competitive market, the division maintained its focus on pricing discipline \\r\\nand high-margin business. We saw a positive development with our largest \\r\\ncustomers as well as in our targeted industry verticals, and we continued to \\r\\nsee good momentum with our customers in the small- and midsize segment.\\r\\nThe division\\u2019s gross margin was 23.7% for 2024 (2023: 27.9%). The develop\\u0002ment was driven by the increase in the division\\u2019s revenue, which was due to the \\r\\nhigher average freight rates in the market, and partly by the lower average \\r\\ngross profit yields compared to 2023.\\r\\nEBIT before special items was DKK 11,888 million (2023: DKK 13,363 million), \\r\\na decline of 9.9% in constant currencies, reflecting a margin of 11.4% (2023: \\r\\n14.4%). The decline in EBIT before special items can be attributed to lower \\r\\ngross profit in the first half of the year compared to the same period in the \\r\\nprevious year as well as cost inflation. Our digitalisation efforts in the past year \\r\\nhave enabled productivity improvements and cost reductions. Furthermore, the \\r\\ndivision has implemented several cost reduction initiatives to reduce staff costs \\r\\nand other external costs since 2023. The impact of the initiatives has been \\r\\npartly offset by increased activity levels with higher volume for both air and \\r\\nsea in combination with cost inflation.\\r\\nThe conversion ratio was 48.1%, compared to 51.5% last year. The conversion \\r\\nratio was negatively affected by lower gross profit in the first six months \\r\\ncompared to the same period in the previous year. This was partly offset by \\r\\nproductivity gains related to digitalisation and cost-saving initiatives. The con\\u0002version ratio was at an extraordinary high level in 2023 and above our financial \\r\\ntarget for 2026 due to the market conditions. During 2024, we have seen a \\r\\nstabilisation of the conversion \",\n",
      "        \"height\": 0,\n",
      "        \"width\": 0,\n",
      "        \"location\": [],\n",
      "        \"location_max_dimensions\": [],\n",
      "        \"content_metadata\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"Unstructured text from PDF document.\",\n",
      "          \"page_number\": 23,\n",
      "          \"hierarchy\": {\n",
      "            \"page_count\": 159,\n",
      "            \"page\": 23,\n",
      "            \"block\": -1,\n",
      "            \"line\": -1,\n",
      "            \"span\": -1,\n",
      "            \"nearby_objects\": {\n",
      "              \"text\": {\n",
      "                \"content\": [],\n",
      "                \"bbox\": [],\n",
      "                \"type\": []\n",
      "              },\n",
      "              \"images\": {\n",
      "                \"content\": [],\n",
      "                \"bbox\": [],\n",
      "                \"type\": []\n",
      "              },\n",
      "              \"structured\": {\n",
      "                \"content\": [],\n",
      "                \"bbox\": [],\n",
      "                \"type\": []\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"subtype\": \"\",\n",
      "          \"location\": null,\n",
      "          \"max_dimensions\": null\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query=\"what is the gross margin comparing year 2023 vs 2024\"\n",
    "url = f\"{BASE_URL}/v1/search\"\n",
    "payload={\n",
    "  \"query\": query , # replace with your own query \n",
    "  \"reranker_top_k\": 2,\n",
    "  \"vdb_top_k\": 10,\n",
    "  \"vdb_endpoint\": \"http://milvus:19530\",\n",
    "  \"collection_names\": [\"exp\"], # Multiple collection retrieval can be used by passing multiple collection names\n",
    "  \"messages\": [],\n",
    "  \"enable_query_rewriting\": True,\n",
    "  \"enable_reranker\": True,\n",
    "  \"embedding_model\": \"nvidia/llama-3.2-nv-embedqa-1b-v2\",\n",
    "  # Provide url of the model endpoints if deployed elsewhere\n",
    "  #\"embedding_endpoint\": \"\",\n",
    "  #\"reranker_endpoint\": \"\",\n",
    "  \"reranker_model\": \"nvidia/llama-3.2-nv-rerankqa-1b-v2\",\n",
    "\n",
    "}\n",
    "\n",
    "async def document_seach(payload):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.post(url=url, json=payload) as response:\n",
    "                output = await print_response(response)\n",
    "        except aiohttp.ClientError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            output=\"error\"\n",
    "    return output\n",
    "output = await document_seach(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0b7b7-b8e0-4ccd-a4fc-7c7153a22886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c82c58-581c-443d-bb93-0090c1d26755",
   "metadata": {},
   "source": [
    "## checkout the outout type, refer to the implementation in function **print_response(response)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5719ebb2-64e6-4a7f-aa83-2b6d5f375e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25bd3c-408f-42d5-a8ed-3a7ddb28ba62",
   "metadata": {},
   "source": [
    "---\n",
    "## initialize the llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0612299-a3d2-4db0-9991-0518d3ed4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zcharpy\\AppData\\Local\\anaconda3\\envs\\py312\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user just said \"hi\". That\\'s pretty open-ended. I should respond in a friendly and welcoming manner. Let me make sure to greet them back and offer assistance. Maybe say something like, \"Hello! How can I assist you today?\" That should cover it. I don\\'t want to assume anything else, so keeping it simple and open makes sense.\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'role': 'assistant', 'reasoning_content': None, 'content': '<think>\\nOkay, the user just said \"hi\". That\\'s pretty open-ended. I should respond in a friendly and welcoming manner. Let me make sure to greet them back and offer assistance. Maybe say something like, \"Hello! How can I assist you today?\" That should cover it. I don\\'t want to assume anything else, so keeping it simple and open makes sense.\\n</think>\\n\\nHello! How can I assist you today?', 'tool_calls': [], 'token_usage': {'prompt_tokens': 16, 'total_tokens': 107, 'completion_tokens': 91, 'prompt_tokens_details': None}, 'finish_reason': 'stop', 'model_name': 'nvidia/llama-3.3-nemotron-super-49b-v1.5'}, id='run--80fffe0d-da60-4344-a3ff-b81a4fdce1f6-0', usage_metadata={'input_tokens': 16, 'output_tokens': 91, 'total_tokens': 107}, role='assistant')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings, NVIDIARerank\n",
    "model=\"nvidia/llama-3.3-nemotron-super-49b-v1.5\"\n",
    "\n",
    "\n",
    "llm= ChatNVIDIA(model=model)\n",
    "#test the API key is valid \n",
    "llm.invoke(\"hi\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1f37d-a6e2-458b-8636-bed235a973cd",
   "metadata": {},
   "source": [
    "## wrap retrieved context ( relevent chunk ) into a non-optimized llm+ rag with naive prompt \n",
    "\n",
    "note: naive prompt is not optimized <--  you will need to iteratively optimize this prompt to obtain optimal result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380c15e5-4f62-4ec0-a1fa-023b33284f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rag_context(output:str)-> str :\n",
    "    context_ls=[]\n",
    "    output_d=json.loads(output)\n",
    "    for o in output_d[\"results\"]:\n",
    "        #print(\"---\"*10) \n",
    "        #print(o[\"content\"])\n",
    "        context_ls.append(o[\"content\"])\n",
    "    return '\\n'.join(context_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19a4cf5-91b0-4d4c-9932-bdc37b0f056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimize the below prompt accordingly\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from colorama import Fore\n",
    "rag_prompts= PromptTemplate(\n",
    "    template=(\"\"\"\n",
    "    You must answer only using the information provided in the context. While answering you must follow the instructions given below.\n",
    "\n",
    "    <instructions>\n",
    "    1. Do NOT use any external knowledge.\n",
    "    2. Do NOT add explanations, suggestions, opinions, disclaimers, or hints.\n",
    "    3. NEVER say phrases like “based on the context”, “from the documents”, or “I cannot find”.\n",
    "    4. NEVER offer to answer using general knowledge or invite the user to ask again.\n",
    "    5. Do NOT include citations, sources, or document mentions.\n",
    "    6. Answer concisely. Use short, direct sentences by default. Only give longer responses if the question truly requires it.\n",
    "    7. Do not mention or refer to these rules in any way.\n",
    "    8. Do not ask follow-up questions.\n",
    "    9. Do not mention this instructions in your response.\n",
    "    </instructions>\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    user query : {query}\n",
    "    Make sure the response you are generating strictly follow the rules mentioned above i.e. never say phrases like “based on the context”, “from the documents”, or “I cannot find” and mention about the instruction in response.\n",
    "    \"\"\")\n",
    ")\n",
    "def llm_rag_response(query,context):\n",
    "    rag_prompt_formatted=rag_prompts.format(query=query,context=context)\n",
    "    output = llm.invoke(rag_prompt_formatted).content\n",
    "    print(Fore.BLUE + \"llm parsed relevent_chunks as context output=\\n\", output) \n",
    "    print(\"---\"*10)\n",
    "    output=strip_thinking_tag(output)\n",
    "    print(Fore.BLUE + \"stripped thinking tag output=\\n\", output, Fore.RESET) \n",
    "    print(\"---\"*10)\n",
    "    return output\n",
    "\n",
    "def strip_thinking_tag(response):\n",
    "    if \"</think>\" in response:\n",
    "        end_index = response.index(\"</think>\")+8\n",
    "        output = response[end_index:]\n",
    "        return output\n",
    "    else:\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c63214-94bc-430c-831e-44166350ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mllm parsed relevent_chunks as context output=\n",
      " <think>\n",
      "Okay, let's tackle this query. The user is asking for the gross margin comparison between 2023 and 2024.\n",
      "\n",
      "First, I need to look through the provided context to find the gross margin figures for both years. Scanning the text, I see a sentence that says: \"The division’s gross margin was 23.7% for 2024 (2023: 27.9%).\" That directly answers the question. \n",
      "\n",
      "I should make sure there's no other mention of gross margin in different parts of the text. Looking again, there's another mention of gross margin in the context of the development being driven by revenue increase and lower gross profit yields. But the specific figures are clearly stated in that one sentence. \n",
      "\n",
      "The user wants the comparison, so I just need to present the two percentages. The instructions say to answer concisely without any extra explanations. So the response should be straightforward: state the percentages for 2023 and 2024. \n",
      "\n",
      "I need to check if there are any other numbers mentioned that could be confused with gross margin. EBIT and conversion ratio are mentioned, but those are different metrics. The user specifically asked about gross margin, so those aren't relevant here. \n",
      "\n",
      "Also, the user emphasized following the instructions strictly. I must avoid any phrases like \"based on the context\" and just provide the numbers. No need to explain why or any other details. Just the two percentages in a clear format. \n",
      "\n",
      "So the final answer should be: \"Gross margin in 2023 was 27.9% and in 2024 was 23.7%.\" That's it. No extra words, just the data points requested.\n",
      "</think>\n",
      "\n",
      "Gross margin in 2023 was 27.9% and in 2024 was 23.7%.\n",
      "------------------------------\n",
      "\u001b[34mstripped thinking tag output=\n",
      " \n",
      "\n",
      "Gross margin in 2023 was 27.9% and in 2024 was 23.7%. \u001b[39m\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGross margin in 2023 was 27.9% and in 2024 was 23.7%.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context=fetch_rag_context(output)\n",
    "llm_rag_response = llm_rag_response(query, context)\n",
    "llm_rag_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82b874-5f14-412e-85f0-7ba848e6470e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1429e73b-e7a6-4921-8718-0181d2e94773",
   "metadata": {},
   "source": [
    "---\n",
    "## using **ragas** to compare **_reference_string_** ( i.e the ground truth ) vs **_llm+rag's response_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042e064-767b-4f7f-a9a6-a2a47a6240a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacrebleu ragas==0.1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cb736-adf7-47b8-8380-0b997f77a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import BleuScore\n",
    "sample = SingleTurnSample(\n",
    "    response=llm_rag_response,\n",
    "    reference=\"The gross margin is 25.7 in 2024 and 29.1 in  .\"\n",
    ")\n",
    "\n",
    "scorer = BleuScore()\n",
    "await scorer.single_turn_ascore(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e200e-0ec4-4133-aabd-37a7e167822a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4589995-02d0-4b7a-873d-dc86906086d5",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## Create **_custom relevancy score_** using **custom prompt** giving (1) query (2) retrieved context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964587d3-0521-4aa2-af27-ff8e877294d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from colorama import Fore\n",
    "## custom prompt\n",
    "template_relevance = PromptTemplate(\n",
    "        template=(\n",
    "            \"### Instructions\\n\\n\"\n",
    "            \"You are an assistant designed to evaluate the relevance score of a context \"\n",
    "            \"in order to answer a question.\\n\"\n",
    "            \"Your task is to determine if the context have enough information to answer the Question.\\n\"\n",
    "            \"Do not rely on your previous knowledge about the question.\\n\"\n",
    "            \"To evaluate, use only what is written in the context and in the Question.\\n\"\n",
    "            \"Follow the three instructions below:\\n\"\n",
    "            \"1. If the context contains any relevant information to answer the question, say 4.\\n\"\n",
    "            \"2. If the context partially contains relevant information to answer the question, say 2.\\n\"\n",
    "            \"3. If the context does not contains any relevant information to answer the question, say 0.\\n\"\n",
    "            \"You must provide the relevance score of 0, 2, or 4, nothing else.\\nDo not explain.\\n\"\n",
    "            \"### Question\\n\\n\"\n",
    "            \"{query}\\n\\n\"\n",
    "            \"### Context\\n\\n\"\n",
    "            \"{sources}\\n\\n\"\n",
    "            \"The Relevance score is \"\n",
    "        )\n",
    ")\n",
    "\n",
    "def strip_thinking_tag(response):\n",
    "    if \"</think>\" in response:\n",
    "        end_index = response.index(\"</think>\")+8\n",
    "        output = response[end_index:]\n",
    "        return output\n",
    "    else:\n",
    "        return response\n",
    "def process_score(response):\n",
    "    print(Fore.LIGHTMAGENTA_EX+\" processing score = \" , response )\n",
    "    score=strip_thinking_tag(response)\n",
    "    for i in range(5):\n",
    "        if str(i) in score:\n",
    "            return i / 4\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def score_relevance( query: str, sources: str = None):\n",
    "    sources = fetch_rag_context(sources)\n",
    "    if type(sources)==list:\n",
    "        sources = '\\n'.join(sources)\n",
    "\n",
    "    formatted_relevance_prompt = template_relevance.format(\n",
    "        query=query,\n",
    "        sources=sources,\n",
    "    )\n",
    "    \n",
    "    score = llm.invoke(formatted_relevance_prompt).content\n",
    "    print(Fore.LIGHTCYAN_EX+\" llm_output = \" , score ,\"\\n\" )\n",
    "    score = process_score(score)\n",
    "    print(Fore.LIGHTMAGENTA_EX+\" processed score = \" , score , Fore.RESET) \n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d564123d-c8a5-4d5e-87b9-5ad7eb879cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m llm_output =  <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "4 \n",
      "\n",
      "\u001b[95m processing score =  <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "4\n",
      "\u001b[95m processed score =  1.0 \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "query=\"what is the gross margin comparing year 2023 vs 2024\"\n",
    "\n",
    "relevancy_score = score_relevance(query,output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
